{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Challenge\n",
    "\n",
    "Wine experts can identify wines from specific vineyards through smell and taste, but the factors that give different wines their individual charateristics are actually based on their chemical composition.\n",
    "\n",
    "In this challenge, you must train a classification model to analyze the chemical and visual features of wine samples and classify them based on their cultivar (grape variety).\n",
    "\n",
    "> **Citation**: The data used in this exercise was originally collected by Forina, M. et al.\n",
    ">\n",
    "> PARVUS - An Extendible Package for Data Exploration, Classification and Correlation.\n",
    "Institute of Pharmaceutical and Food Analysis and Technologies, Via Brigata Salerno,\n",
    "16147 Genoa, Italy.\n",
    ">\n",
    "> It can be downloaded from the UCI dataset repository (Dua, D. and Graff, C. (2019). [UCI Machine Learning Repository]([http://archive.ics.uci.edu/ml). Irvine, CA: University of California, School of Information and Computer Science). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the data\n",
    "\n",
    "Run the following cell to load a CSV file of wine data, which consists of 12 numeric features and a classification label with the following classes:\n",
    "\n",
    "- **0** (*variety A*)\n",
    "- **1** (*variety B*)\n",
    "- **2** (*variety C*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the training dataset\n",
    "data = pd.read_csv('data/wine.csv')\n",
    "sample = data.sample(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your challenge is to explore the data and train a classification model that achieves an overall *Recall* metric of over 0.95 (95%).\n",
    "\n",
    "> **Note**: There is no single \"correct\" solution. A sample solution is provided in [03 - Wine Classification Solution.ipynb](03%20-%20Wine%20Classification%20Solution.ipynb)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate a model\n",
    "\n",
    "Add markdown and code cells as required to to explore the data, train a model, and evaluate the model's predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wine_classes = [\"Variety A\", \"Variety B\", \"Variety C\"]\n",
    "print(sample.columns[0:12].values, 'Variety')\n",
    "for index, row in data.sample(10).iterrows():\n",
    "    print('[', \n",
    "          row[0], \n",
    "          row[1], \n",
    "          row[2], \n",
    "          row[3], \n",
    "          int(row[4]),\n",
    "          row[5], \n",
    "          row[6], \n",
    "          row[7], \n",
    "          row[8], \n",
    "          row[9], \n",
    "          row[10], \n",
    "          row[11],\n",
    "          row[12],\n",
    "          int(row[13]), ']', wine_classes[int(row[13])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "data_features = [\n",
    "    'Alcohol',\n",
    "    'Malic_acid',\n",
    "    'Ash',\n",
    "    'Alcalinity',\n",
    "    'Magnesium',\n",
    "    'Phenols',\n",
    "    'Flavanoids',\n",
    "    'Nonflavanoids',\n",
    "    'Proanthocyanins',\n",
    "    'Color_intensity',\n",
    "    'Hue',\n",
    "    'OD280_315_of_diluted_wines',\n",
    "    'Proline'\n",
    "]\n",
    "data_label = 'WineVariety'\n",
    "\n",
    "for col in data_features:\n",
    "    data.boxplot(column=col, by=data_label, figsize=(6,6))\n",
    "    plt.title(col)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = data[data_features].values, data[data_label].values\n",
    "\n",
    "for n in range(0,4):\n",
    "    print(\"Wine\", str(n+1), \"\\n Features:\", list(X[n]), \"\\n Label:\", y[n])\n",
    "\n",
    "# Split data 70%-30% into training set and test set\n",
    "x_data_train, x_data_test, y_data_train, y_data_test = train_test_split(X, y,\n",
    "                                                                        test_size=0.30,\n",
    "                                                                        random_state=0,\n",
    "                                                                        stratify=y)\n",
    "\n",
    "print('Training Set: %d\\nTest Set: %d \\n' % (x_data_train.shape[0], x_data_test.shape[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following code can be skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Set regularization rate\n",
    "reg = 0.1\n",
    "\n",
    "# train a logistic regression model on the training set\n",
    "multi_model = LogisticRegression(C=1/reg, solver='lbfgs', multi_class='auto', max_iter=10000).fit(x_data_train, y_data_train)\n",
    "print(multi_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_predictions = multi_model.predict(x_data_test)\n",
    "print('Predicted labels: ', data_predictions[:15])\n",
    "print('Actual labels:    ', y_data_test[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_data_test, data_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "print(\"Overall Accuracy:\", accuracy_score(y_data_test, data_predictions))\n",
    "print(\"Overall Precision:\", precision_score(y_data_test, data_predictions, average='macro'))\n",
    "print(\"Overall Recall:\", recall_score(y_data_test, data_predictions, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Print the confusion matrix\n",
    "mcm = confusion_matrix(y_data_test, data_predictions)\n",
    "print(mcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(mcm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(wine_classes))\n",
    "plt.xticks(tick_marks, wine_classes, rotation=45)\n",
    "plt.yticks(tick_marks, wine_classes)\n",
    "plt.xlabel(\"Predicted Wine Varieties\")\n",
    "plt.ylabel(\"Actual Wine Varieties\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Get class probability scores\n",
    "data_prob = multi_model.predict_proba(x_data_test)\n",
    "\n",
    "# Get ROC metrics for each class\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "thresh = {}\n",
    "for i in range(len(wine_classes)):\n",
    "    fpr[i], tpr[i], thresh[i] = roc_curve(y_data_test, data_prob[:,i], pos_label=i)\n",
    "\n",
    "# Plot the ROC chart\n",
    "plt.plot(fpr[0], tpr[0], linestyle='--', color='orange', label=wine_classes[0] + ' vs Rest')\n",
    "plt.plot(fpr[1], tpr[1], linestyle='--', color='green', label=wine_classes[1] + ' vs Rest')\n",
    "plt.plot(fpr[2], tpr[2], linestyle='--', color='blue', label=wine_classes[2] + ' vs Rest')\n",
    "plt.title('Multiclass ROC curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = roc_auc_score(y_data_test, data_prob, multi_class='ovr')\n",
    "print('Average AUC:', auc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define preprocessing for numeric columns (scale them)\n",
    "feature_columns = [0,1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "feature_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "# Create preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('preprocess', feature_transformer, feature_columns)])\n",
    "\n",
    "# Create training pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regressor', SVC(probability=True))])\n",
    "\n",
    "# Fit the pipeline to train a linear regression model on the training set\n",
    "multi_model = pipeline.fit(x_data_train, y_data_train)\n",
    "print(multi_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions from test data\n",
    "data_predictions = multi_model.predict(x_data_test)\n",
    "data_prob = multi_model.predict_proba(x_data_test)\n",
    "\n",
    "#Overall metrics\n",
    "print(\"Overall Accuracy:\", accuracy_score(y_data_test, data_predictions))\n",
    "print(\"Overall Precision:\", precision_score(y_data_test, data_predictions, average='macro'))\n",
    "print(\"Overall Recall:\", recall_score(y_data_test, data_predictions, average='macro'))\n",
    "print(\"Average AUC:\", roc_auc_score(y_data_test, data_prob, multi_class='ovr'))\n",
    "\n",
    "# Confusion matrix\n",
    "plt.imshow(mcm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(wine_classes))\n",
    "plt.xticks(tick_marks, wine_classes, rotation=45)\n",
    "plt.yticks(tick_marks, wine_classes)\n",
    "plt.xlabel(\"Predicted Wine Varieties\")\n",
    "plt.ylabel(\"Actual Wine Varieties\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the model with new data observation\n",
    "\n",
    "When you're happy with your model's predictive performance, save it and then use it to predict classes for the following two new wine samples:\n",
    "\n",
    "- \\[13.72,1.43,2.5,16.7,108,3.4,3.67,0.19,2.04,6.8,0.89,2.87,1285\\]\n",
    "- \\[12.37,0.94,1.36,10.6,88,1.98,0.57,0.28,0.42,1.95,1.05,1.82,520\\]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model as a pickle file\n",
    "filename = './wine_model.pkl'\n",
    "joblib.dump(multi_model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "multi_model = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Array of two feature arrays\n",
    "x_new = np.array([\n",
    "    [13.72,1.43,2.5,16.7,108,3.4,3.67,0.19,2.04,6.8,0.89,2.87,1285],\n",
    "    [12.37,0.94,1.36,10.6,88,1.98,0.57,0.28,0.42,1.95,1.05,1.82,520]])\n",
    "\n",
    "# Call the web service, passing the input data\n",
    "predictions = multi_model.predict(x_new)\n",
    "\n",
    "# Get the predicted classes\n",
    "for prediction in predictions:\n",
    "    print(prediction, '(' + wine_classes[prediction] + ')')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
